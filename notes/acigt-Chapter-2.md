# Nash Equilibrium

## 2.1 - Strategic Games
- Every player simultaniously choses their sole plan of action.
- N = players; i = player; A_i = set of actions with preferences (action, preference);  
- Players have to have actions (can't have random unneeded players)
- The preference function of each action **is dependent on the other player's actions**
  - ie. if I choose rock, I will have 1 preference defined for if you choose paper vs if you choose scissor.
  - Different from a "decision problem" because you care about what the other players choose.

 This model is most useful when we define a set of consequences that are accociated with action profiles
 [are action profiles the same as strategies?]
 We can add random chance
 - Ω = a set of probabilities applied to consequences
 - A × Ω → C (aka the preference of your action = the chance that it will happen * it's awesomeness)
   - In other words, if you have an action which gives you a 10% chance to win a million dollars, it's 10x worse than having an action that gives you a 100% chance to win a million dollars. You multiply the optimality of the outcome by the chance it will happen.

     
<img width="165" alt="screen shot 2016-11-12 at 2 37 19 pm" src="https://cloud.githubusercontent.com/assets/706123/20240412/911bbc70-a8e5-11e6-9e50-65fc5a6131ee.png">

- in this picture, w_1, w_2 are the payoffs of players 1 and 2 respectively when the players pick those outcomes
- Players are often assumed to act rationally
- Players only have the model to work off of when picking their actions
- In this book players are assumed to have played the game in the past
- The actions of previous games cannot effect the actions of the current game   

## 2.2 - Nash Equilibrium

## 2.3 - Examples


